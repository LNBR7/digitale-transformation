{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306c81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tkinter as tk\n",
    "from datetime import datetime\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import threading\n",
    "import os\n",
    "import shutil\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ensure model directory exists\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Load AI\n",
    "vectorizer = joblib.load(\"models/nace_vectorizer.pkl\")\n",
    "nace_model = joblib.load(\"models/nace_model.pkl\")\n",
    "\n",
    "\n",
    "# Combined risk keyword dictionary: English and German\n",
    "risk_keywords_combined = {\n",
    "    \"Severity\": {\n",
    "        \"HIGH\": [\"critical\", \"severe\", \"catastrophic\", \"unacceptable\", \"kritisch\", \"schwerwiegend\", \"katastrophal\", \"inakzeptabel\"],\n",
    "        \"MEDIUM\": [\"moderate\", \"considerable\", \"noticeable\", \"moderat\", \"erheblich\", \"merklich\"],\n",
    "        \"LOW\": [\"minor\", \"negligible\", \"minimal\", \"geringfügig\", \"unbedeutend\", \"minimal\"]\n",
    "    },\n",
    "    \"Probability\": {\n",
    "        \"HIGH\": [\"likely\", \"frequent\", \"common\", \"probable\", \"wahrscheinlich\", \"häufig\", \"regelmäßig\", \"oft\"],\n",
    "        \"MEDIUM\": [\"possible\", \"occasional\", \"might happen\", \"möglich\", \"gelegentlich\", \"denkbar\"],\n",
    "        \"LOW\": [\"unlikely\", \"rare\", \"seldom\", \"unwahrscheinlich\", \"selten\", \"kaum\"]\n",
    "    },\n",
    "    \"Scope\": {\n",
    "        \"GLOBAL\": [\"worldwide\", \"global\", \"international\", \"weltweit\", \"global\", \"international\"],\n",
    "        \"REGIONAL\": [\"regional\", \"continental\", \"european\", \"asian\", \"regional\", \"kontinental\", \"europaweit\"],\n",
    "        \"LOCAL\": [\"local\", \"community\", \"municipal\", \"national\", \"lokal\", \"gemeindebezogen\", \"kommunal\", \"national\"]\n",
    "    },\n",
    "    \"Urgency\": {\n",
    "        \"IMMEDIATE\": [\"urgent\", \"immediately\", \"as soon as possible\", \"critical\", \"sofort\", \"dringend\", \"unverzüglich\", \"kritisch\"],\n",
    "        \"MEDIUM TERM\": [\"soon\", \"in the near future\", \"within months\", \"zeitnah\", \"in nächster zeit\", \"innerhalb von monaten\"],\n",
    "        \"LONG TERM\": [\"long term\", \"future\", \"eventually\", \"in the coming years\", \"langfristig\", \"zukünftig\", \"in den kommenden jahren\"]\n",
    "    },\n",
    "    \"NACE_Relevant\": {\n",
    "        \"HIGH\": [\"direct impact\", \"core industry\", \"sector-critical\", \"direkte auswirkung\", \"zentrale branche\", \"branchenkritisch\"],\n",
    "        \"MEDIUM\": [\"related sector\", \"adjacent industry\", \"verwandte branche\", \"benachbarter sektor\"],\n",
    "        \"LOW\": [\"minor connection\", \"indirect relevance\", \"geringe verbindung\", \"indirekte relevanz\"]\n",
    "    },\n",
    "    \"Company_Influence\": {\n",
    "        \"HIGH\": [\"company decision\", \"internal policy\", \"corporate governance\", \"unternehmensentscheidung\", \"interne richtlinie\", \"konzernführung\"],\n",
    "        \"MEDIUM\": [\"partnership\", \"supply chain\", \"influence\", \"partnerschaft\", \"lieferkette\", \"einflussnahme\"],\n",
    "        \"LOW\": [\"external\", \"third party\", \"limited control\", \"externe stelle\", \"drittanbieter\", \"begrenzte kontrolle\"]\n",
    "    },\n",
    "    \"Data_Availability\": {\n",
    "        \"HIGH\": [\"detailed report\", \"comprehensive\", \"full access\", \"detaillierter bericht\", \"umfassend\", \"vollständige daten\"],\n",
    "        \"MEDIUM\": [\"partial data\", \"limited insights\", \"some statistics\", \"teilweise daten\", \"eingeschränkter einblick\", \"einige statistiken\"],\n",
    "        \"LOW\": [\"no data\", \"not disclosed\", \"incomplete information\", \"keine daten\", \"nicht veröffentlicht\", \"unvollständig\"]\n",
    "    },\n",
    "    \"Regulation\": {\n",
    "        \"HIGH\": [\"strict law\", \"mandatory\", \"compliance required\", \"strenges gesetz\", \"verbindlich\", \"compliance erforderlich\"],\n",
    "        \"MEDIUM\": [\"recommended\", \"framework\", \"some regulation\", \"empfohlen\", \"rahmenbedingungen\", \"teilweise reguliert\"],\n",
    "        \"LOW\": [\"voluntary\", \"no legal requirement\", \"unregulated\", \"freiwillig\", \"keine gesetzliche pflicht\", \"unreguliert\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to guess risk parameter levels from text (EN + DE)\n",
    "def guess_risk_parameters_from_text(text):\n",
    "    result = {}\n",
    "    lower_text = text.lower()\n",
    "\n",
    "    for param, levels in risk_keywords_combined.items():\n",
    "        found_level = \"UNKNOWN\"\n",
    "        for level, keywords in levels.items():\n",
    "            for kw in keywords:\n",
    "                if re.search(rf\"\\b{re.escape(kw)}\\b\", lower_text):\n",
    "                    found_level = level\n",
    "                    break\n",
    "            if found_level != \"UNKNOWN\":\n",
    "                break\n",
    "        result[param] = found_level\n",
    "    return result\n",
    "\n",
    "# Keywords for NACE classification\n",
    "nace_keywords = {\n",
    "    \"A1\": [\n",
    "        \"agriculture\", \"crop\", \"palm oil\", \"rice\", \"cotton\", \"cocoa\", \"coffee\", \"sugar\",\n",
    "        \"landwirtschaft\", \"ackerbau\", \"palmenöl\", \"reis\", \"baumwolle\", \"kakao\", \"kaffee\", \"zucker\",\n",
    "        \"palm\", \"palmöl\", \"kinderarbeit\", \"child labour\", \"child labor\", \"zwangsarbeit\", \"forced labour\", \"forced labor\",\n",
    "        \"arbeitsbedingungen\", \"poverty\", \"armut\", \"racism\", \"rassismus\" \"tobacco\", \"tabak\", \"reisanbau\",\n",
    "        \"fairtrade\", \"fair trade\", \"slavery\", \"sklaverei\", \"human rights\", \"menschenrechte\", \"human cost\"\n",
    "    ],\n",
    "    \"A2\": [\n",
    "        \"forestry\", \"wood\", \"logging\", \"timber\",\n",
    "        \"forstwirtschaft\", \"holz\", \"abholzung\", \"forst\", \"holzernte\"\n",
    "    ],\n",
    "    \"A3\": [\n",
    "        \"fishing\", \"aquaculture\", \"fish\", \"shrimp\",\n",
    "        \"fischerei\", \"aquakultur\", \"fisch\", \"garnelen\"\n",
    "    ],\n",
    "    \"C10\": [\n",
    "        \"cocoa\", \"chocolate\", \"coffee\", \"tea\", \"sugar\", \"food\",\n",
    "        \"kakao\", \"schokolade\", \"kaffee\", \"tee\", \"zucker\", \"lebensmittel\", \"nahrungsmittel\",\n",
    "        \"palmöl\", \"palm oil\", \"kinderarbeit\", \"child labour\", \"child labor\",\n",
    "        \"zwangsarbeit\", \"forced labour\", \"forced labor\"\n",
    "    ],\n",
    "    \"C12\":  [\n",
    "        \"tobacco\", \"tabak\", \"cigar\", \"zigarre\", \"zigarette\", \"cigarette\"\n",
    "    ],\n",
    "    \"C13\": [\n",
    "        \"textile\", \"fabric\", \"yarn\", \"garment\",\n",
    "        \"textilien\", \"stoff\", \"garn\", \"gewebe\", \"textil\",\n",
    "        \"kinderarbeit\", \"child labour\", \"child labor\", \"zwangsarbeit\", \"forced labour\", \"forced labor\",\n",
    "        \"arbeitsbedingungen\", \"wages\", \"löhne\", \"poverty\", \"armut\", \"racism\", \"rassismus\",\n",
    "        \"fairtrade\", \"fair trade\", \"slavery\", \"sklaverei\", \"human rights\", \"menschenrechte\", \"human cost\"\n",
    "    ],\n",
    "    \"C14\": [\n",
    "        \"clothing\", \"apparel\", \"garment\", \"t-shirt\", \"shirt\", \"jeans\",\n",
    "        \"kleidung\", \"bekleidung\", \"oberbekleidung\", \"hemd\",\n",
    "        \"kinderarbeit\", \"child labour\", \"child labor\", \"zwangsarbeit\", \"forced labour\", \"forced labor\",\n",
    "        \"arbeitsbedingungen\", \"wages\", \"löhne\", \"poverty\", \"armut\", \"racism\", \"rassismus\",\n",
    "        \"fairtrade\", \"fair trade\", \"slavery\", \"sklaverei\", \"human rights\", \"menschenrechte\", \"human cost\"\n",
    "    ],\n",
    "    \"C15\": [\n",
    "        \"leather\", \"shoe\", \"footwear\",\n",
    "        \"leder\", \"schuh\", \"schuhe\", \"fußbekleidung\"\n",
    "    ],\n",
    "    \"C20\": [\n",
    "        \"chemical\", \"pharmaceutical\", \"fertilizer\", \"pesticide\", \"plastic\",\n",
    "        \"chemie\", \"chemikalien\", \"dünger\", \"pestizid\", \"kunststoff\"\n",
    "    ],\n",
    "    \"C21\": [\n",
    "        \"pharma\", \"pharmaceutical\", \"medicine\",\n",
    "        \"pharmazeutisch\", \"medizin\", \"arznei\", \"medikament\"\n",
    "    ],\n",
    "    \"C22\": [\n",
    "        \"plastic product\", \"plastic\",\n",
    "        \"kunststoff\", \"plastik\", \"kunststoffprodukt\"\n",
    "    ],\n",
    "    \"C26\": [\n",
    "        \"electronic\", \"semiconductor\", \"battery\",\n",
    "        \"elektronik\", \"elektronisch\", \"halbleiter\", \"batterie\"\n",
    "    ],\n",
    "    \"D35\": [\n",
    "        \"energy\", \"electricity\", \"power\",\n",
    "        \"energie\", \"strom\", \"elektrizität\"\n",
    "    ],\n",
    "    \"E38\": [\n",
    "        \"waste\", \"wastes\", \"recycling\", \"disposal\",\n",
    "        \"abfall\", \"entsorgung\"\n",
    "    ],\n",
    "    \"E39\": [\n",
    "        \"remediation\", \"cleanup\", \"waste\", \"wastes\",\n",
    "        \"sanierung\", \"reinigung\", \"aufbereitung\", \"abfall\"\n",
    "    ],\n",
    "    \"H49\": [\n",
    "        \"transport\", \"freight\", \"truck\", \"rail\", \"logistics\", \"infrastructure\",\n",
    "        \"fracht\", \"lkw\", \"bahn\", \"schiene\", \"logistik\", \"infrastruktur\", \"lieferkette\"\n",
    "    ],\n",
    "    \"H50\": [\n",
    "        \"shipping\", \"sea freight\", \"infrastructure\",\n",
    "        \"schifffahrt\", \"seehandel\", \"seefracht\", \"infrastruktur\"\n",
    "    ],\n",
    "    \"H52\": [\n",
    "        \"warehouse\", \"storage\", \"logistics\",\n",
    "        \"lager\", \"lagerung\", \"logistik\", \"lagerhaltung\"\n",
    "    ],\n",
    "    \"G46\": [\n",
    "        \"wholesale\", \"trade\",\n",
    "        \"großhandel\", \"handel\"\n",
    "    ],\n",
    "    \"G47\": [\n",
    "        \"retail\", \"store\", \"shop\",\n",
    "        \"einzelhandel\", \"laden\", \"geschäft\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def get_domain_name(url):\n",
    "    \"\"\"Extract domain as source/publisher fallback\"\"\"\n",
    "    domain = urlparse(url).netloc\n",
    "    return domain.replace(\"www.\", \"\")\n",
    "\n",
    "def extract_meta_author(soup):\n",
    "    \"\"\"Try to get author/publisher info from meta tags\"\"\"\n",
    "    meta_author = soup.find(\"meta\", {\"name\": \"author\"})\n",
    "    if meta_author and meta_author.get(\"content\"):\n",
    "        return meta_author[\"content\"].strip()\n",
    "\n",
    "    og_site = soup.find(\"meta\", {\"property\": \"og:site_name\"})\n",
    "    if og_site and og_site.get(\"content\"):\n",
    "        return og_site[\"content\"].strip()\n",
    "\n",
    "    publisher = soup.find(\"meta\", {\"name\": \"publisher\"})\n",
    "    if publisher and publisher.get(\"content\"):\n",
    "        return publisher[\"content\"].strip()\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "def extract_publish_date(soup):\n",
    "    \"\"\"Try to extract publish date from meta tags\"\"\"\n",
    "    tag = soup.find(\"meta\", {\"property\": \"article:published_time\"})\n",
    "    if tag and tag.get(\"content\"):\n",
    "        return tag[\"content\"][:10]  # YYYY-MM-DD\n",
    "    return None\n",
    "\n",
    "def fallback_title(soup):\n",
    "    \"\"\"Try to extract title if article.title fails\"\"\"\n",
    "    og_title = soup.find(\"meta\", {\"property\": \"og:title\"})\n",
    "    if og_title and og_title.get(\"content\"):\n",
    "        return og_title[\"content\"]\n",
    "    if soup.title:\n",
    "        return soup.title.string.strip()\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Trustworthiness scoring\n",
    "def score_sources(source_name, author_name, language, date_str, sector_relevant, has_sources, independent):\n",
    "    score = 0\n",
    "\n",
    "    # 1. Source and authority of the information\n",
    "\n",
    "    trusted_high = [\"UN\", \"OECD\", \"ILO\", \"EU\", \"Bundesministerium\", \"Federal Ministry\", \"University\", \"Max Planck\",\n",
    "    \"UNEP\", \"UNICEF\", \"WHO\", \"World Bank\", \"Weltbank\", \"BMZ\", \"BAFA\", \"GIZ\",\n",
    "    \"Fraunhofer\", \"Helmholtz\", \"Amnesty\", \"Greenpeace\", \"FAO\", \"UNDP\"]\n",
    "    trusted_medium = [\"NGO\", \"Fairtrade\", \"McKinsey\", \"Oxfam\", \"Vision\",\n",
    "    \"AidEnvironment\", \"Foodwatch\", \"Transparency International\", \"WWF\", \"Brot für die Welt\",\n",
    "    \"Verité\", \"World Vision\", \"Bridge Michigan\"]\n",
    "    source = str(source_name)\n",
    "    if any(key.lower() in source.lower() for key in trusted_high):\n",
    "        score += 10\n",
    "    elif any(key.lower() in source.lower() for key in trusted_medium):\n",
    "        score += 7\n",
    "    else:\n",
    "        score += 4\n",
    "\n",
    "    # 2. Actuality\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        tage_alt = (datetime.today() - date).days\n",
    "        if tage_alt < 365:\n",
    "            score += 10\n",
    "        elif tage_alt < 1095:\n",
    "            score += 8\n",
    "        elif tage_alt < 2190:\n",
    "            score += 6\n",
    "        else:\n",
    "            score += 3\n",
    "    except:\n",
    "        score += 5  # Fallback\n",
    "\n",
    "    # 3. Author competence\n",
    "    competent_authors = [\"Dr.\", \"Prof.\", \"Expert\", \"Researcher\", \"PhD\", \"M.Sc.\", \"Msc\", \"Dipl.-Ing.\", \"Diplom\", \"Mag.\", \"Mba\"]\n",
    "    if any(k.lower() in author_name.lower() for k in competent_authors):\n",
    "        score += 10\n",
    "    else:\n",
    "        score += 6\n",
    "\n",
    "    # 4. Transparency\n",
    "    score += 10 if has_sources else 5\n",
    "\n",
    "    # 5. Language\n",
    "    if language.lower() == \"english\":\n",
    "        score += 10\n",
    "    elif language.lower() == \"deutsch\" or language.lower() == \"german\":\n",
    "        score += 7\n",
    "    else:\n",
    "        score += 5\n",
    "\n",
    "    # 6. Sector relevance\n",
    "    score += 10 if sector_relevant else 5\n",
    "\n",
    "    # 7. Independency\n",
    "    score += 10 if independent else 5\n",
    "\n",
    "    # Final score \n",
    "    final_score = round(score / 7, 1)  # average score of all 7 criteria\n",
    "    return final_score\n",
    "\n",
    "def score_risk(severity, probability, scope, urgency, nace_relevant, company_influence, data_availability, regulation):\n",
    "\n",
    "    # Scoring scales\n",
    "    scale = {\"HIGH\": 10, \"MEDIUM\": 7, \"LOW\": 4}\n",
    "    scope_scale = {\"GLOBAL\": 10, \"REGIONAL\": 7, \"LOCAL\": 4}\n",
    "    urgency_scale = {\"IMMEDIATE\": 10, \"MEDIUM TERM\": 7, \"LONG TERM\": 4}\n",
    "\n",
    "    # Highest possible score: 8 × 10 points = 80\n",
    "    score = 0\n",
    "    score += scale.get(severity, 5)\n",
    "    score += scale.get(probability, 5)\n",
    "    score += scope_scale.get(scope, 5)\n",
    "    score += urgency_scale.get(urgency, 5)\n",
    "    score += scale.get(nace_relevant, 5)\n",
    "    score += scale.get(company_influence, 5)\n",
    "    score += scale.get(data_availability, 5)\n",
    "    score += scale.get(regulation, 5)\n",
    "\n",
    "    # 1-10 scale for final score\n",
    "    final_score = round((score / 80) * 10, 1)\n",
    "    return final_score\n",
    "\n",
    "\n",
    "# Check if entry is already shown in the GUI\n",
    "def entry_already_in_gui(title, author):\n",
    "    for child in tree.get_children():\n",
    "        values = tree.item(child)[\"values\"]\n",
    "        if len(values) >= 2 and values[0] == title and values[1] == author:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def scrape_url_and_process(url):\n",
    "    try:\n",
    "        # Load article content using newspaper3k\n",
    "        article = Article(url, language='de')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        # Fallbacks via BeautifulSoup\n",
    "        html = requests.get(url, timeout=10).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Extract key data\n",
    "        title = article.title or fallback_title(soup)\n",
    "        author = \", \".join(article.authors) if article.authors else extract_meta_author(soup)\n",
    "        text = article.text or \"\"\n",
    "\n",
    "        # Guess risk parameter levels from text using keyword heuristics\n",
    "        guessed_risk = guess_risk_parameters_from_text(title + \" \" + text)\n",
    "\n",
    "        # Prepare risk parameters with guessed values\n",
    "        risk_params = {\n",
    "        key: guessed_risk.get(key, \"UNKNOWN\") for key in [\n",
    "        \"Severity\", \"Probability\", \"Scope\", \"Urgency\",\n",
    "        \"NACE_Relevant\", \"Company_Influence\", \"Data_Availability\", \"Regulation\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        source = article.source_url or get_domain_name(url)\n",
    "        language = \"German\"\n",
    "\n",
    "        # Date fallback\n",
    "        if article.publish_date:\n",
    "            date_str = article.publish_date.strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            date_str = extract_publish_date(soup) or \"2020-01-01\"\n",
    "\n",
    "        # Default values\n",
    "        sector_relevant = True\n",
    "        has_sources = True\n",
    "        independent = True\n",
    "\n",
    "        # Calculate trust score\n",
    "        trust = score_sources(source, author, language, date_str, sector_relevant, has_sources, independent)\n",
    "\n",
    "        # Ask user to confirm or complete the guessed parameters\n",
    "        manual_result = manual_complete_risk_parameters(risk_params)\n",
    "\n",
    "\n",
    "        if manual_result:\n",
    "            severity = manual_result[\"Severity\"]\n",
    "            probability = manual_result[\"Probability\"]\n",
    "            scope = manual_result[\"Scope\"]\n",
    "            urgency = manual_result[\"Urgency\"]\n",
    "            nace_relevant = manual_result[\"NACE_Relevant\"]\n",
    "            company_influence = manual_result[\"Company_Influence\"]\n",
    "            data_availability = manual_result[\"Data_Availability\"]\n",
    "            regulation = manual_result[\"Regulation\"]\n",
    "        else:\n",
    "            severity = risk_params[\"Severity\"]\n",
    "            probability = risk_params[\"Probability\"]\n",
    "            scope = risk_params[\"Scope\"]\n",
    "            urgency = risk_params[\"Urgency\"]\n",
    "            nace_relevant = risk_params[\"NACE_Relevant\"]\n",
    "            company_influence = risk_params[\"Company_Influence\"]\n",
    "            data_availability = risk_params[\"Data_Availability\"]\n",
    "            regulation = risk_params[\"Regulation\"]\n",
    "\n",
    "\n",
    "        # Compute risk score\n",
    "        risk = score_risk(\n",
    "            severity, probability, scope, urgency, nace_relevant,\n",
    "            company_influence, data_availability, regulation\n",
    "        )\n",
    "\n",
    "        # Combine AI-based and keyword-based NACE assignment\n",
    "\n",
    "        # 1. Prediction via trained model\n",
    "        X_new = vectorizer.transform([title + \" \" + text])\n",
    "        predicted_nace = nace_model.predict(X_new)[0]\n",
    "\n",
    "        # 2. Keyword-based NACE matching\n",
    "        matched_codes = []\n",
    "        combined_text = f\"{title} {text}\".lower()\n",
    "\n",
    "        for code, keywords in nace_keywords.items():\n",
    "            if any(re.search(rf\"\\b{re.escape(kw)}\\b\", combined_text, flags=re.IGNORECASE) for kw in keywords):\n",
    "                matched_codes.append(code)\n",
    "\n",
    "        # 3. Merge both sets, remove duplicates\n",
    "        all_nace_codes = set([predicted_nace] + matched_codes)\n",
    "        nace_codes = \", \".join(sorted(all_nace_codes)) if all_nace_codes else \"Undefined\"\n",
    "\n",
    "        # Timestamp for entry\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        return {\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"NACE_Assignment\": nace_codes,\n",
    "            \"Trust_Score\": trust,\n",
    "            \"Risk_Score\": risk,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Scraper Error\", f\"Failed to extract from URL:\\n{e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def scrape_manual_url():\n",
    "    def analyze():\n",
    "        url = entry.get()\n",
    "        result = scrape_url_and_process(url)\n",
    "        if result and not entry_already_in_gui(result[\"Title\"], result[\"Author\"]):\n",
    "            tree.insert(\"\", tk.END, values=list(result.values()))\n",
    "        popup.destroy()\n",
    "\n",
    "    popup = tk.Toplevel(root)\n",
    "    popup.title(\"Enter Article URL\")\n",
    "    popup.geometry(\"600x150\")\n",
    "\n",
    "    label = tk.Label(popup, text=\"Please enter the article URL:\", font=(\"Arial\", 12))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "    entry = tk.Entry(popup, width=80)\n",
    "    entry.pack(pady=5)\n",
    "\n",
    "    button = tk.Button(popup, text=\"Analyze\", command=analyze, bg=\"#4CAF50\", fg=\"white\")\n",
    "    button.pack(pady=10)\n",
    "\n",
    "def manual_complete_risk_parameters(risk_dict):\n",
    "    popup = tk.Toplevel(root)\n",
    "    popup.title(\"Manual Risk Parameter Completion\")\n",
    "    popup.geometry(\"420x420\")\n",
    "\n",
    "    label = tk.Label(popup, text=\"Please confirm or complete the risk parameters:\", font=(\"Arial\", 11))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "    fields = [\"Severity\", \"Probability\", \"Scope\", \"Urgency\", \"NACE_Relevant\",\n",
    "              \"Company_Influence\", \"Data_Availability\", \"Regulation\"]\n",
    "\n",
    "    dropdown_values = {\n",
    "        \"Severity\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "        \"Probability\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "        \"Scope\": [\"GLOBAL\", \"REGIONAL\", \"LOCAL\"],\n",
    "        \"Urgency\": [\"IMMEDIATE\", \"MEDIUM TERM\", \"LONG TERM\"],\n",
    "        \"NACE_Relevant\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "        \"Company_Influence\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "        \"Data_Availability\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "        \"Regulation\": [\"HIGH\", \"MEDIUM\", \"LOW\"]\n",
    "    }\n",
    "\n",
    "    entries = {}\n",
    "\n",
    "    for field in fields:\n",
    "        frame = tk.Frame(popup)\n",
    "        frame.pack(pady=5, padx=15, fill=\"x\")\n",
    "\n",
    "        guessed_value = risk_dict.get(field, \"\")\n",
    "        if guessed_value and guessed_value != \"UNKNOWN\":\n",
    "            label_text = f\"{field} (Detected: {guessed_value})\"\n",
    "        else:\n",
    "            label_text = f\"{field} (Not detected please select)\"\n",
    "\n",
    "        tk.Label(frame, text=label_text, font=(\"Arial\", 10), width=30, anchor=\"w\").pack(side=\"left\")\n",
    "\n",
    "        var = tk.StringVar(value=guessed_value if guessed_value != \"UNKNOWN\" else \"\")\n",
    "        dropdown = ttk.Combobox(frame, textvariable=var, values=dropdown_values[field], state=\"readonly\", width=15)\n",
    "        dropdown.pack(side=\"left\")\n",
    "\n",
    "        entries[field] = var\n",
    "\n",
    "    def confirm():\n",
    "        popup.result = {field: var.get() for field, var in entries.items()}\n",
    "        popup.destroy()\n",
    "\n",
    "    def skip():\n",
    "        popup.result = None\n",
    "        popup.destroy()\n",
    "\n",
    "    btn_frame = tk.Frame(popup)\n",
    "    btn_frame.pack(pady=15)\n",
    "\n",
    "    tk.Button(btn_frame, text=\"Confirm\", command=confirm, bg=\"green\", fg=\"white\", width=10).pack(side=\"left\", padx=10)\n",
    "    tk.Button(btn_frame, text=\"Skip\", command=skip, width=10).pack(side=\"right\", padx=10)\n",
    "\n",
    "    popup.grab_set()\n",
    "    root.wait_window(popup)\n",
    "\n",
    "    return popup.result\n",
    "\n",
    "# Analyze input Excel file\n",
    "def analyze_file(path):\n",
    "    try:\n",
    "        df_input = pd.read_excel(path)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error loading file\", str(e))\n",
    "        return\n",
    "\n",
    "    filename = \"nace_source_evaluation.xlsx\"\n",
    "    if os.path.exists(filename):\n",
    "        df_existing = pd.read_excel(filename)\n",
    "    else:\n",
    "        df_existing = pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "    skipped_titles = []\n",
    "\n",
    "    for _, row in df_input.iterrows():\n",
    "        title = str(row[\"Title\"])\n",
    "        author = str(row[\"Author\"])\n",
    "\n",
    "        if entry_already_in_gui(title, author):\n",
    "            skipped_titles.append(title)\n",
    "            continue\n",
    "\n",
    "        # Combine title and author for better AI prediction (if full text not available)\n",
    "        X_new = vectorizer.transform([f\"{title} {author}\"])\n",
    "        predicted_nace = nace_model.predict(X_new)[0]\n",
    "\n",
    "\n",
    "        # Keyword-based matching (allows multiple matches)\n",
    "        matched_codes = []\n",
    "        combined_text = f\"{title} {author}\".lower()\n",
    "\n",
    "        for code, keywords in nace_keywords.items():\n",
    "            if any(re.search(rf\"\\b{re.escape(kw)}\\b\", combined_text, flags=re.IGNORECASE) for kw in keywords):\n",
    "                matched_codes.append(code)\n",
    "\n",
    "        # Combine AI and keyword codes (avoid duplicates)\n",
    "        all_nace_codes = set([predicted_nace] + matched_codes)\n",
    "        nace_codes = \", \".join(sorted(all_nace_codes)) if all_nace_codes else \"Undefined\"\n",
    "\n",
    "\n",
    "\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        source = str(row[\"Source\"])\n",
    "        language = str(row[\"Language\"])\n",
    "        date_str = str(row[\"Date\"])\n",
    "        sector_relevant = bool(row[\"Sector_Relevant\"])\n",
    "        has_sources = bool(row[\"Has_Sources\"])\n",
    "        independent = bool(row[\"Independent\"])\n",
    "\n",
    "        trust = score_sources(\n",
    "    source, author, language, date_str,\n",
    "    sector_relevant, has_sources, independent\n",
    ")\n",
    "        \n",
    "        severity = str(row[\"Severity\"])\n",
    "        probability = str(row[\"Probability\"])\n",
    "        scope = str(row[\"Scope\"])\n",
    "        urgency = str(row[\"Urgency\"])\n",
    "        nace_relevant = str(row[\"NACE_Relevant\"])\n",
    "        company_influence = str(row[\"Company_Influence\"])\n",
    "        data_availability = str(row[\"Data_Availability\"])\n",
    "        regulation = str(row[\"Regulation\"])\n",
    "\n",
    "        risk = score_risk(severity, probability, scope, urgency,\n",
    "                  nace_relevant, company_influence, data_availability, regulation)\n",
    "        \n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"NACE_Assignment\": nace_codes,\n",
    "            \"Trust_Score\": trust,\n",
    "            \"Risk_Score\": risk,\n",
    "            \"Timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "    if skipped_titles:\n",
    "        print(\"Skipped entries:\", skipped_titles)\n",
    "        info_text = \"The following titles have already been analyzed and were skipped:\\n\\n\" + \"\\n\".join(skipped_titles)\n",
    "        messagebox.showinfo(\"Info\", info_text)\n",
    "\n",
    "    if not results:\n",
    "        return\n",
    "\n",
    "    df_output = pd.DataFrame(results)\n",
    "\n",
    "    if not df_existing.empty:\n",
    "        df_total = pd.concat([df_existing, df_output], ignore_index=True)\n",
    "    else:\n",
    "        df_total = df_output\n",
    "\n",
    "    df_total.to_excel(filename, index=False)\n",
    "    return df_output\n",
    "\n",
    "# Load and process file from GUI\n",
    "def load_file():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "    if not path:\n",
    "        return\n",
    "\n",
    "    df = analyze_file(path)\n",
    "    if df is not None:\n",
    "        for _, row in df.iterrows():\n",
    "            title = row[\"Title\"]\n",
    "            author = row[\"Author\"]\n",
    "            if not entry_already_in_gui(title, author):\n",
    "                tree.insert(\"\", tk.END, values=list(row))\n",
    "\n",
    "        processed_folder = \"processed\"\n",
    "        os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "        filename = os.path.basename(path)\n",
    "        target_path = os.path.join(processed_folder, filename)\n",
    "\n",
    "        try:\n",
    "            shutil.move(path, target_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "\n",
    "        messagebox.showinfo(\"Done\", \"Analysis completed and saved as 'nace_source_evaluation.xlsx'\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"NACE Source Analysis Tool\")\n",
    "root.geometry(\"1450x750\")\n",
    "root.configure(bg=\"#f0f4f8\")\n",
    "\n",
    "frame_top = tk.Frame(root, bg=\"#f0f4f8\")\n",
    "frame_top.pack(pady=20)\n",
    "\n",
    "lbl_title = tk.Label(frame_top, text=\"NACE Classification and Trust Evaluation\", font=(\"Arial\", 16, \"bold\"), bg=\"#f0f4f8\")\n",
    "lbl_title.pack(pady=5)\n",
    "\n",
    "btn_load = tk.Button(frame_top, text=\"Load & Analyze Excel File\", command=load_file, font=(\"Arial\", 12), bg=\"#4CAF50\", fg=\"white\", padx=10, pady=5)\n",
    "btn_load.pack()\n",
    "\n",
    "btn_scrape_url = tk.Button(frame_top, text=\"Analyze Web Article\", command=scrape_manual_url, font=(\"Arial\", 12), bg=\"#2196F3\", fg=\"white\", padx=10, pady=5)\n",
    "btn_scrape_url.pack(pady=5)\n",
    "\n",
    "# --- INPUT ---\n",
    "input_fields = [\n",
    "    \"Title\", \"Source\", \"Author\", \"Language\", \"Date\", \"Sector_Relevant\",\n",
    "    \"Has_Sources\", \"Independent\", \"Severity\", \"Probability\", \"Scope\",\n",
    "    \"Urgency\", \"NACE_Relevant\", \"Company_Influence\", \"Data_Availability\", \"Regulation\"\n",
    "]\n",
    "\n",
    "entry_frame = tk.Frame(root, bg=\"#f0f4f8\")\n",
    "entry_frame.pack(fill=\"x\", padx=10, pady=10)\n",
    "\n",
    "entry_widgets = {}\n",
    "\n",
    "# Dropdown values for specific fields\n",
    "dropdown_fields = {\n",
    "    \"Severity\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "    \"Probability\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "    \"Scope\": [\"GLOBAL\", \"REGIONAL\", \"LOCAL\"],\n",
    "    \"Urgency\": [\"IMMEDIATE\", \"MEDIUM TERM\", \"LONG TERM\"],\n",
    "    \"Sector_Relevant\": [\"True\", \"False\"],\n",
    "    \"Has_Sources\": [\"True\", \"False\"],\n",
    "    \"Independent\": [\"True\", \"False\"],\n",
    "    \"NACE_Relevant\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "    \"Company_Influence\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "    \"Data_Availability\": [\"HIGH\", \"MEDIUM\", \"LOW\"],\n",
    "    \"Regulation\": [\"HIGH\", \"MEDIUM\", \"LOW\"]\n",
    "}\n",
    "\n",
    "# Split fields into two rows\n",
    "row1_fields = input_fields[:8]\n",
    "row2_fields = input_fields[8:]\n",
    "\n",
    "for row_fields in [row1_fields, row2_fields]:\n",
    "    row = tk.Frame(entry_frame, bg=\"#f0f4f8\")\n",
    "    row.pack(pady=5)\n",
    "    for field in row_fields:\n",
    "        sub = tk.Frame(row, bg=\"#f0f4f8\")\n",
    "        sub.pack(side=\"left\", padx=5)\n",
    "        tk.Label(sub, text=f\"{field}:\", font=(\"Arial\", 11), bg=\"#f0f4f8\").pack(anchor=\"w\")\n",
    "\n",
    "        if field == \"Language\":\n",
    "            language_options = [\"English\", \"German\", \"Other\"]\n",
    "            var = tk.StringVar()\n",
    "            dropdown = ttk.Combobox(sub, textvariable=var, values=language_options, width=14, state=\"readonly\")\n",
    "            dropdown.pack()\n",
    "            entry_widgets[field] = dropdown\n",
    "\n",
    "        elif field == \"Date\":\n",
    "            from datetime import datetime\n",
    "            year_options = [str(year) for year in range(datetime.now().year, 2000, -1)]\n",
    "            var = tk.StringVar()\n",
    "            dropdown = ttk.Combobox(sub, textvariable=var, values=year_options, width=14, state=\"readonly\")\n",
    "            dropdown.pack()\n",
    "            entry_widgets[field] = dropdown\n",
    "\n",
    "        elif field in dropdown_fields:\n",
    "            var = tk.StringVar()\n",
    "            dropdown = ttk.Combobox(sub, textvariable=var, values=dropdown_fields[field], width=14, state=\"readonly\")\n",
    "            dropdown.pack()\n",
    "            entry_widgets[field] = dropdown\n",
    "\n",
    "        else:\n",
    "            entry = tk.Entry(sub, width=16, font=(\"Arial\", 11))\n",
    "            entry.pack()\n",
    "            entry_widgets[field] = entry\n",
    "\n",
    "# Function to open and display the README.md file in a popup window\n",
    "def show_readme_popup():\n",
    "    try:\n",
    "        with open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to load the README file:\\n{e}\")\n",
    "        return\n",
    "\n",
    "    popup = tk.Toplevel(root)\n",
    "    popup.title(\"Instructions / Usage Guide\")\n",
    "    popup.geometry(\"900x600\")\n",
    "\n",
    "    # Scrollable Text widget\n",
    "    text_widget = tk.Text(popup, wrap=\"word\", font=(\"Courier New\", 10))\n",
    "    text_widget.insert(\"1.0\", content)\n",
    "    text_widget.config(state=\"disabled\")  # Make it read-only\n",
    "    text_widget.pack(expand=True, fill=\"both\")\n",
    "\n",
    "    # Vertical scrollbar\n",
    "    scrollbar = tk.Scrollbar(popup, command=text_widget.yview)\n",
    "    scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "    text_widget.config(yscrollcommand=scrollbar.set)\n",
    "\n",
    "# Button to open the usage guide / README\n",
    "btn_readme = tk.Button(\n",
    "    frame_top,\n",
    "    text=\"Open Instructions (README)\",\n",
    "    command=show_readme_popup,\n",
    "    font=(\"Arial\", 12),\n",
    "    bg=\"#FF9800\",\n",
    "    fg=\"white\",\n",
    "    padx=10,\n",
    "    pady=5\n",
    ")\n",
    "btn_readme.pack(pady=5)\n",
    "\n",
    "\n",
    "# Manual Entry Function \n",
    "def add_manual_entry():\n",
    "    values = {k: entry_widgets[k].get().strip() for k in input_fields}\n",
    "    \n",
    "    # Title and Source are mandatory\n",
    "    if not values[\"Title\"] or not values[\"Source\"]:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter both Title and Source.\")\n",
    "        return\n",
    "\n",
    "    filename = filedialog.askopenfilename(filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "    if not filename:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df_existing = pd.read_excel(filename)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error reading file\", str(e))\n",
    "        return\n",
    "\n",
    "    if ((df_existing[\"Title\"] == values[\"Title\"]) & (df_existing[\"Author\"] == values[\"Source\"])).any():\n",
    "        messagebox.showinfo(\"Duplicate\", \"This entry already exists in the file.\")\n",
    "        return\n",
    "\n",
    "    # Combine AI and keyword-based NACE classification for manual entry\n",
    "    X_new = vectorizer.transform([f\"{values['Title']} {values.get('Author', '')}\"])\n",
    "    predicted_nace = nace_model.predict(X_new)[0]\n",
    "\n",
    "    # NACE Assignment\n",
    "    matched_codes = []\n",
    "    for code, keywords in nace_keywords.items():\n",
    "        if any(re.search(rf\"\\b{kw}\\b\", values[\"Title\"], re.IGNORECASE) for kw in keywords):\n",
    "            matched_codes.append(code)\n",
    "\n",
    "    all_nace_codes = set([predicted_nace] + matched_codes)\n",
    "    nace_codes = \", \".join(sorted(all_nace_codes)) if all_nace_codes else \"Undefined\"\n",
    "\n",
    "\n",
    "    # Trust Score Calculation\n",
    "    trust = score_sources(\n",
    "        values[\"Source\"],\n",
    "        values.get(\"Author\", \"\"),\n",
    "        values.get(\"Language\", \"\"),\n",
    "        values.get(\"Date\", \"\"),\n",
    "        values.get(\"Sector_Relevant\", \"\").lower() == \"true\",\n",
    "        values.get(\"Has_Sources\", \"\").lower() == \"true\",\n",
    "        values.get(\"Independent\", \"\").lower() == \"true\"\n",
    "    )\n",
    "\n",
    "    # Risk Score Calculation\n",
    "    risk = score_risk(\n",
    "        values.get(\"Severity\", \"\"), values.get(\"Probability\", \"\"), values.get(\"Scope\", \"\"),\n",
    "        values.get(\"Urgency\", \"\"), values.get(\"NACE_Relevant\", \"\"), values.get(\"Company_Influence\", \"\"),\n",
    "        values.get(\"Data_Availability\", \"\"), values.get(\"Regulation\", \"\")\n",
    "    )\n",
    "\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    author = values.get(\"Author\") or values[\"Source\"]\n",
    "\n",
    "    new_row = {\n",
    "        \"Title\": values[\"Title\"],\n",
    "        \"Author\": author,\n",
    "        \"NACE_Assignment\": nace_codes,\n",
    "        \"Trust_Score\": trust,\n",
    "        \"Risk_Score\": risk,\n",
    "        \"Timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "    df_updated = pd.concat([df_existing, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    try:\n",
    "        df_updated.to_excel(filename, index=False)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error writing to file\", str(e))\n",
    "        return\n",
    "\n",
    "    if not entry_already_in_gui(values[\"Title\"], values[\"Source\"]):\n",
    "        tree.insert(\"\", tk.END, values=list(new_row.values()))\n",
    "\n",
    "    messagebox.showinfo(\"Success\", \"Entry added successfully.\")\n",
    "\n",
    "# Button\n",
    "btn_add_manual = tk.Button(entry_frame, text=\"Add Entry to File\", command=add_manual_entry,\n",
    "font=(\"Arial\", 12), bg=\"#2196F3\", fg=\"white\", padx=10, pady=5)\n",
    "btn_add_manual.pack(pady=10)\n",
    "\n",
    "# Legend Section \n",
    "legend_frame = tk.Frame(root, bg=\"#f0f4f8\", pady=10)\n",
    "legend_frame.pack(fill=\"x\", padx=10)\n",
    "\n",
    "# Trust Score Legend\n",
    "trust_label = tk.Label(\n",
    "    legend_frame,\n",
    "    text=\"Trust Score: 10 = High Trust, 1 = Low Trust\",\n",
    "    font=(\"Arial\", 11),\n",
    "    bg=\"#f0f4f8\",\n",
    "    fg=\"#333\"\n",
    ")\n",
    "trust_label.pack(anchor=\"w\", padx=5)\n",
    "\n",
    "# Risk Score Legend\n",
    "risk_label = tk.Label(\n",
    "    legend_frame,\n",
    "    text=\"Risk Score: 10 = High Risk, 1 = Low Risk\",\n",
    "    font=(\"Arial\", 11),\n",
    "    bg=\"#f0f4f8\",\n",
    "    fg=\"#333\"\n",
    ")\n",
    "risk_label.pack(anchor=\"w\", padx=5)\n",
    "# END LEGEND \n",
    "\n",
    "frame_table = tk.Frame(root)\n",
    "frame_table.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "columns = [\"Title\", \"Author\", \"NACE_Assignment\", \"Trust_Score\", \"Risk_Score\", \"Timestamp\"]\n",
    "tree = ttk.Treeview(frame_table, columns=columns, show=\"headings\", height=20)\n",
    "\n",
    "# Set column widths and alignment\n",
    "tree.column(\"Title\", width=450, anchor=\"w\")\n",
    "tree.column(\"Author\", width=200, anchor=\"w\")\n",
    "tree.column(\"NACE_Assignment\", width=120, anchor=\"center\")\n",
    "tree.column(\"Trust_Score\", width=60, anchor=\"center\")\n",
    "tree.column(\"Risk_Score\", width=60, anchor=\"center\")\n",
    "tree.column(\"Timestamp\", width=120, anchor=\"center\")\n",
    "\n",
    "# Enable sorting on column headers\n",
    "def sort_treeview_column(treeview, col, reverse):\n",
    "    # Extract data\n",
    "    data = [(treeview.set(k, col), k) for k in treeview.get_children(\"\")]\n",
    "    # Try sorting numerically, fallback to text\n",
    "    try:\n",
    "        data.sort(key=lambda t: float(t[0]), reverse=reverse)\n",
    "    except ValueError:\n",
    "        data.sort(key=lambda t: t[0].lower(), reverse=reverse)\n",
    "    # Reorder in tree\n",
    "    for index, (val, k) in enumerate(data):\n",
    "        treeview.move(k, '', index)\n",
    "    # Toggle direction\n",
    "    treeview.heading(col, command=lambda: sort_treeview_column(treeview, col, not reverse))\n",
    "\n",
    "# Set headings and make them clickable\n",
    "for col in columns:\n",
    "    tree.heading(col, text=col, command=lambda _col=col: sort_treeview_column(tree, _col, False))\n",
    "    tree.column(col, anchor=\"w\", width=230)\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\"Treeview.Heading\", font=(\"Arial\", 11, \"bold\"))\n",
    "style.configure(\"Treeview\", font=(\"Arial\", 10))\n",
    "\n",
    "tree.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Watchdog handler\n",
    "class ExcelHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.src_path.endswith(\".xlsx\"):\n",
    "            df = analyze_file(event.src_path)\n",
    "            if df is not None:\n",
    "                tree.after(0, update_gui, df)\n",
    "                processed_folder = \"processed\"\n",
    "                os.makedirs(processed_folder, exist_ok=True)\n",
    "                filename = os.path.basename(event.src_path)\n",
    "                target_path = os.path.join(processed_folder, filename)\n",
    "                try:\n",
    "                    shutil.move(event.src_path, target_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error moving file: {e}\")\n",
    "\n",
    "# Update GUI with new data\n",
    "def update_gui(df):\n",
    "    for _, row in df.iterrows():\n",
    "        title = row[\"Title\"]\n",
    "        author = row[\"Author\"]\n",
    "        if not entry_already_in_gui(title, author):\n",
    "            tree.insert(\"\", tk.END, values=list(row))\n",
    "\n",
    "# Folder monitoring\n",
    "def monitor_folder(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    event_handler = ExcelHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path=path, recursive=False)\n",
    "    observer.start()\n",
    "\n",
    "monitor_thread = threading.Thread(\n",
    "    target=monitor_folder, \n",
    "    args=(\"incoming_sources\",), \n",
    "    daemon=True\n",
    ")\n",
    "monitor_thread.start()\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
