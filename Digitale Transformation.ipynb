{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306c81e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\domin\\anaconda3\\envs\\DataChallenge\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3653, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas\\_libs\\index.pyx\", line 147, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 176, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Source'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\domin\\anaconda3\\envs\\DataChallenge\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\domin\\AppData\\Local\\Temp\\ipykernel_26052\\4084142122.py\", line 276, in load_file\n",
      "    df = analyze_file(path)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\domin\\AppData\\Local\\Temp\\ipykernel_26052\\4084142122.py\", line 220, in analyze_file\n",
      "    source = str(row[\"Source\"])\n",
      "                 ~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\domin\\anaconda3\\envs\\DataChallenge\\Lib\\site-packages\\pandas\\core\\series.py\", line 1007, in __getitem__\n",
      "    return self._get_value(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\domin\\anaconda3\\envs\\DataChallenge\\Lib\\site-packages\\pandas\\core\\series.py\", line 1116, in _get_value\n",
      "    loc = self.index.get_loc(label)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\domin\\anaconda3\\envs\\DataChallenge\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3655, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Source'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tkinter as tk\n",
    "from datetime import datetime\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import threading\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Keywords for NACE classification\n",
    "nace_keywords = {\n",
    "    \"A1\": [\n",
    "        \"agriculture\", \"crop\", \"palm oil\", \"rice\", \"cotton\", \"cocoa\", \"coffee\", \"sugar\",\n",
    "        \"landwirtschaft\", \"ackerbau\", \"palmenöl\", \"reis\", \"baumwolle\", \"kakao\", \"kaffee\", \"zucker\"\n",
    "    ],\n",
    "    \"A2\": [\n",
    "        \"forestry\", \"wood\", \"logging\", \"timber\",\n",
    "        \"forstwirtschaft\", \"holz\", \"abholzung\", \"forst\", \"holzernte\"\n",
    "    ],\n",
    "    \"A3\": [\n",
    "        \"fishing\", \"aquaculture\", \"fish\", \"shrimp\",\n",
    "        \"fischerei\", \"aquakultur\", \"fisch\", \"garnelen\"\n",
    "    ],\n",
    "    \"C10\": [\n",
    "        \"cocoa\", \"chocolate\", \"coffee\", \"tea\", \"sugar\", \"food\",\n",
    "        \"kakao\", \"schokolade\", \"kaffee\", \"tee\", \"zucker\", \"lebensmittel\", \"nahrungsmittel\"\n",
    "    ],\n",
    "    \"C13\": [\n",
    "        \"textile\", \"fabric\", \"yarn\", \"garment\",\n",
    "        \"textilien\", \"stoff\", \"garn\", \"gewebe\", \"textil\"\n",
    "    ],\n",
    "    \"C14\": [\n",
    "        \"clothing\", \"apparel\", \"garment\", \"t-shirt\", \"shirt\", \"jeans\",\n",
    "        \"kleidung\", \"bekleidung\", \"oberbekleidung\", \"t-shirt\", \"hemd\", \"jeans\"\n",
    "    ],\n",
    "    \"C15\": [\n",
    "        \"leather\", \"shoe\", \"footwear\",\n",
    "        \"leder\", \"schuh\", \"schuhe\", \"fußbekleidung\"\n",
    "    ],\n",
    "    \"C20\": [\n",
    "        \"chemical\", \"pharmaceutical\", \"fertilizer\", \"pesticide\", \"plastic\",\n",
    "        \"chemie\", \"chemikalien\", \"dünger\", \"pestizid\", \"kunststoff\"\n",
    "    ],\n",
    "    \"C21\": [\n",
    "        \"pharma\", \"pharmaceutical\", \"medicine\",\n",
    "        \"pharma\", \"pharmazeutisch\", \"medizin\", \"arznei\", \"medikament\"\n",
    "    ],\n",
    "    \"C22\": [\n",
    "        \"plastic product\", \"plastic\",\n",
    "        \"kunststoff\", \"plastik\", \"kunststoffprodukt\"\n",
    "    ],\n",
    "    \"C26\": [\n",
    "        \"electronics\", \"electronic\", \"semiconductor\", \"battery\",\n",
    "        \"elektronik\", \"elektronisch\", \"halbleiter\", \"batterie\"\n",
    "    ],\n",
    "    \"D35\": [\n",
    "        \"energy\", \"electricity\", \"power\",\n",
    "        \"energie\", \"strom\", \"elektrizität\"\n",
    "    ],\n",
    "    \"E38\": [\n",
    "        \"waste\", \"recycling\", \"disposal\",\n",
    "        \"abfall\", \"recycling\", \"entsorgung\"\n",
    "    ],\n",
    "    \"E39\": [\n",
    "        \"remediation\", \"cleanup\",\n",
    "        \"sanierung\", \"reinigung\", \"aufbereitung\"\n",
    "    ],\n",
    "    \"H49\": [\n",
    "        \"transport\", \"freight\", \"truck\", \"rail\",\n",
    "        \"transport\", \"fracht\", \"lkw\", \"bahn\", \"schiene\"\n",
    "    ],\n",
    "    \"H50\": [\n",
    "        \"shipping\", \"sea freight\",\n",
    "        \"schifffahrt\", \"seehandel\", \"seefracht\"\n",
    "    ],\n",
    "    \"H52\": [\n",
    "        \"warehouse\", \"storage\", \"logistics\",\n",
    "        \"lager\", \"lagerung\", \"logistik\", \"lagerhaltung\"\n",
    "    ],\n",
    "    \"G46\": [\n",
    "        \"wholesale\", \"trade\",\n",
    "        \"großhandel\", \"handel\"\n",
    "    ],\n",
    "    \"G47\": [\n",
    "        \"retail\", \"store\", \"shop\",\n",
    "        \"einzelhandel\", \"laden\", \"geschäft\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Trustworthiness scoring\n",
    "def score_sources(source_name, author_name, language, date_str, sector_relevant, has_sources, independent):\n",
    "    score = 0\n",
    "\n",
    "    # 1. Source and authority of the information\n",
    "\n",
    "    trusted_high = [\"UN\", \"OECD\", \"ILO\", \"EU\", \"Bundesministerium\", \"Federal Ministry\", \"University\", \"Max Planck\",\n",
    "    \"UNEP\", \"UNICEF\", \"WHO\", \"World Bank\", \"Weltbank\", \"BMZ\", \"BAFA\", \"GIZ\",\n",
    "    \"Fraunhofer\", \"Helmholtz\", \"Amnesty\", \"Greenpeace\", \"FAO\", \"UNDP\"]\n",
    "    trusted_medium = [\"NGO\", \"Fairtrade\", \"McKinsey\", \"Oxfam\", \"Vision\",\n",
    "    \"AidEnvironment\", \"Foodwatch\", \"Transparency International\", \"WWF\", \"Brot für die Welt\",\n",
    "    \"Verité\", \"World Vision\", \"Bridge Michigan\"]\n",
    "    source = str(source_name)\n",
    "    if any(key.lower() in source.lower() for key in trusted_high):\n",
    "        score += 10\n",
    "    elif any(key.lower() in source.lower() for key in trusted_medium):\n",
    "        score += 7\n",
    "    else:\n",
    "        score += 4\n",
    "\n",
    "    # 2. Actuality\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        tage_alt = (datetime.today() - date).days\n",
    "        if tage_alt < 365:\n",
    "            score += 10\n",
    "        elif tage_alt < 1095:\n",
    "            score += 8\n",
    "        elif tage_alt < 2190:\n",
    "            score += 6\n",
    "        else:\n",
    "            score += 3\n",
    "    except:\n",
    "        score += 5  # Fallback\n",
    "\n",
    "    # 3. Author competence\n",
    "    competent_authors = [\"Dr.\", \"Prof.\", \"Expert\", \"Researcher\", \"PhD\", \"M.Sc.\", \"Msc\", \"Dipl.-Ing.\", \"Diplom\", \"Mag.\", \"Mba\"]\n",
    "    if any(k.lower() in author_name.lower() for k in competent_authors):\n",
    "        score += 10\n",
    "    else:\n",
    "        score += 6\n",
    "\n",
    "    # 4. Transparency\n",
    "    score += 10 if has_sources else 5\n",
    "\n",
    "    # 5. Language\n",
    "    if language.lower() == \"english\":\n",
    "        score += 10\n",
    "    elif language.lower() == \"deutsch\" or language.lower() == \"german\":\n",
    "        score += 7\n",
    "    else:\n",
    "        score += 5\n",
    "\n",
    "    # 6. Sectory relevance\n",
    "    score += 10 if sector_relevant else 5\n",
    "\n",
    "    # 7. Independency\n",
    "    score += 10 if independent else 5\n",
    "\n",
    "    # Final score \n",
    "    final_score = round(score / 7, 1)  # average score of all 7 criteria\n",
    "    return final_score\n",
    "\n",
    "def score_risk(severity, probability, scope, urgency, nace_relevant, company_influence, data_availability, regulation):\n",
    "\n",
    "    # Scoring scales\n",
    "    scale = {\"HIGH\": 10, \"MEDIUM\": 7, \"LOW\": 4}\n",
    "    scope_scale = {\"GLOBAL\": 10, \"REGIONAL\": 7, \"LOCAL\": 4}\n",
    "    urgency_scale = {\"IMMEDIATE\": 10, \"MEDIUM TERM\": 7, \"LONG TERM\": 4}\n",
    "\n",
    "    # Highest possible score: 8 × 10 points = 80\n",
    "    score = 0\n",
    "    score += scale.get(severity, 5)\n",
    "    score += scale.get(probability, 5)\n",
    "    score += scope_scale.get(scope, 5)\n",
    "    score += urgency_scale.get(urgency, 5)\n",
    "    score += scale.get(nace_relevant, 5)\n",
    "    score += scale.get(company_influence, 5)\n",
    "    score += scale.get(data_availability, 5)\n",
    "    score += scale.get(regulation, 5)\n",
    "\n",
    "    # 1-10 scale for final score\n",
    "    final_score = round((score / 80) * 10, 1)\n",
    "    return final_score\n",
    "\n",
    "\n",
    "# Check if entry is already shown in the GUI\n",
    "def entry_already_in_gui(title, author):\n",
    "    for child in tree.get_children():\n",
    "        values = tree.item(child)[\"values\"]\n",
    "        if len(values) >= 2 and values[0] == title and values[1] == author:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Analyze input Excel file\n",
    "def analyze_file(path):\n",
    "    try:\n",
    "        df_input = pd.read_excel(path)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error loading file\", str(e))\n",
    "        return\n",
    "\n",
    "    filename = \"nace_source_evaluation.xlsx\"\n",
    "    if os.path.exists(filename):\n",
    "        df_existing = pd.read_excel(filename)\n",
    "    else:\n",
    "        df_existing = pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "    skipped_titles = []\n",
    "\n",
    "    for _, row in df_input.iterrows():\n",
    "        title = str(row[\"Title\"])\n",
    "        author = str(row[\"Author\"])\n",
    "\n",
    "        if entry_already_in_gui(title, author):\n",
    "            skipped_titles.append(title)\n",
    "            continue\n",
    "\n",
    "        # Assign NACE codes\n",
    "        matched_codes = []\n",
    "        for code, keywords in nace_keywords.items():\n",
    "            if any(re.search(rf\"\\b{kw}\\b\", title, re.IGNORECASE) for kw in keywords):\n",
    "                matched_codes.append(code)\n",
    "        nace_codes = \", \".join(matched_codes) if matched_codes else \"Undefined\"\n",
    "\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        source = str(row[\"Source\"])\n",
    "        language = str(row[\"Language\"])\n",
    "        date_str = str(row[\"Date\"])\n",
    "        sector_relevant = bool(row[\"Sector_Relevant\"])\n",
    "        has_sources = bool(row[\"Has_Sources\"])\n",
    "        independent = bool(row[\"Independent\"])\n",
    "\n",
    "        trust = score_sources(\n",
    "    source, author, language, date_str,\n",
    "    sector_relevant, has_sources, independent\n",
    ")\n",
    "        \n",
    "        severity = str(row[\"Severity\"])\n",
    "        probability = str(row[\"Probability\"])\n",
    "        scope = str(row[\"Scope\"])\n",
    "        urgency = str(row[\"Urgency\"])\n",
    "        nace_relevant = str(row[\"NACE_Relevant\"])\n",
    "        company_influence = str(row[\"Company_Influence\"])\n",
    "        data_availability = str(row[\"Data_Availability\"])\n",
    "        regulation = str(row[\"Regulation\"])\n",
    "\n",
    "        risk = score_risk(severity, probability, scope, urgency,\n",
    "                  nace_relevant, company_influence, data_availability, regulation)\n",
    "        \n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"NACE_Assignment\": nace_codes,\n",
    "            \"Trust_Score\": trust,\n",
    "            \"Risk_Score\": risk,\n",
    "            \"Timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "    if skipped_titles:\n",
    "        info_text = \"The following titles have already been analyzed and were skipped:\\n\\n\" + \"\\n\".join(skipped_titles)\n",
    "        messagebox.showinfo(\"Info\", info_text)\n",
    "\n",
    "    if not results:\n",
    "        return\n",
    "\n",
    "    df_output = pd.DataFrame(results)\n",
    "\n",
    "    if not df_existing.empty:\n",
    "        df_total = pd.concat([df_existing, df_output], ignore_index=True)\n",
    "    else:\n",
    "        df_total = df_output\n",
    "\n",
    "    df_total.to_excel(filename, index=False)\n",
    "    return df_output\n",
    "\n",
    "# Load and process file from GUI\n",
    "def load_file():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "    if not path:\n",
    "        return\n",
    "\n",
    "    df = analyze_file(path)\n",
    "    if df is not None:\n",
    "        for _, row in df.iterrows():\n",
    "            title = row[\"Title\"]\n",
    "            author = row[\"Author\"]\n",
    "            if not entry_already_in_gui(title, author):\n",
    "                tree.insert(\"\", tk.END, values=list(row))\n",
    "\n",
    "        processed_folder = \"processed\"\n",
    "        os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "        filename = os.path.basename(path)\n",
    "        target_path = os.path.join(processed_folder, filename)\n",
    "\n",
    "        try:\n",
    "            shutil.move(path, target_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "\n",
    "        messagebox.showinfo(\"Done\", \"Analysis completed and saved as 'nace_source_evaluation.xlsx'\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"NACE Source Analysis Tool\")\n",
    "root.geometry(\"1200x600\")\n",
    "root.configure(bg=\"#f0f4f8\")\n",
    "\n",
    "frame_top = tk.Frame(root, bg=\"#f0f4f8\")\n",
    "frame_top.pack(pady=20)\n",
    "\n",
    "lbl_title = tk.Label(frame_top, text=\"NACE Classification and Trust Evaluation\", font=(\"Arial\", 16, \"bold\"), bg=\"#f0f4f8\")\n",
    "lbl_title.pack(pady=5)\n",
    "\n",
    "btn_load = tk.Button(frame_top, text=\"Load & Analyze Excel File\", command=load_file, font=(\"Arial\", 12), bg=\"#4CAF50\", fg=\"white\", padx=10, pady=5)\n",
    "btn_load.pack()\n",
    "\n",
    "# --- INPUT ---\n",
    "input_fields = [\n",
    "    \"Title\", \"Source\", \"Author\", \"Language\", \"Date\", \"Sector_Relevant\",\n",
    "    \"Has_Sources\", \"Independent\", \"Severity\", \"Probability\", \"Scope\",\n",
    "    \"Urgency\", \"NACE_Relevant\", \"Company_Influence\", \"Data_Availability\", \"Regulation\"\n",
    "]\n",
    "\n",
    "entry_frame = tk.Frame(root, bg=\"#f0f4f8\")\n",
    "entry_frame.pack(fill=\"x\", padx=10, pady=10)\n",
    "\n",
    "canvas = tk.Canvas(entry_frame, height=50, bg=\"#f0f4f8\")\n",
    "scrollbar = tk.Scrollbar(entry_frame, orient=\"horizontal\", command=canvas.xview)\n",
    "scrollable_input_frame = tk.Frame(canvas, bg=\"#f0f4f8\")\n",
    "\n",
    "scrollable_input_frame.bind(\n",
    "    \"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    ")\n",
    "canvas.create_window((0, 0), window=scrollable_input_frame, anchor=\"nw\")\n",
    "canvas.configure(xscrollcommand=scrollbar.set)\n",
    "\n",
    "canvas.pack(side=\"top\", fill=\"x\", expand=True)\n",
    "scrollbar.pack(side=\"bottom\", fill=\"x\")\n",
    "\n",
    "entry_widgets = {}\n",
    "\n",
    "for idx, field in enumerate(input_fields):\n",
    "    tk.Label(scrollable_input_frame, text=f\"{field}:\", font=(\"Arial\", 12), bg=\"#f0f4f8\")\\\n",
    "        .grid(row=0, column=idx, padx=5, sticky=\"w\")\n",
    "    entry = tk.Entry(scrollable_input_frame, width=20, font=(\"Arial\", 12))\n",
    "    entry.grid(row=1, column=idx, padx=5, pady=5)\n",
    "    entry_widgets[field] = entry\n",
    "\n",
    "def add_manual_entry():\n",
    "    values = {k: entry_widgets[k].get().strip() for k in input_fields}\n",
    "    \n",
    "    # Title and Source are mandatory\n",
    "    if not values[\"Title\"] or not values[\"Source\"]:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter both Title and Source.\")\n",
    "        return\n",
    "\n",
    "    filename = filedialog.askopenfilename(filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "    if not filename:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df_existing = pd.read_excel(filename)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error reading file\", str(e))\n",
    "        return\n",
    "\n",
    "    if ((df_existing[\"Title\"] == values[\"Title\"]) & (df_existing[\"Author\"] == values[\"Source\"])).any():\n",
    "        messagebox.showinfo(\"Duplicate\", \"This entry already exists in the file.\")\n",
    "        return\n",
    "\n",
    "    # NACE-Zuordnung\n",
    "    matched_codes = []\n",
    "    for code, keywords in nace_keywords.items():\n",
    "        if any(re.search(rf\"\\b{kw}\\b\", values[\"Title\"], re.IGNORECASE) for kw in keywords):\n",
    "            matched_codes.append(code)\n",
    "    nace_codes = \", \".join(matched_codes) if matched_codes else \"Undefined\"\n",
    "\n",
    "    # Vertrauens-Score berechnen\n",
    "    trust = score_sources(\n",
    "        values[\"Source\"],\n",
    "        values.get(\"Author\", \"\"),\n",
    "        values.get(\"Language\", \"\"),\n",
    "        values.get(\"Date\", \"\"),\n",
    "        values.get(\"Sector_Relevant\", \"\").lower() == \"true\",\n",
    "        values.get(\"Has_Sources\", \"\").lower() == \"true\",\n",
    "        values.get(\"Independent\", \"\").lower() == \"true\"\n",
    "    )\n",
    "\n",
    "    # Risiko-Score berechnen\n",
    "    risk = score_risk(\n",
    "        values.get(\"Severity\", \"\"), values.get(\"Probability\", \"\"), values.get(\"Scope\", \"\"),\n",
    "        values.get(\"Urgency\", \"\"), values.get(\"NACE_Relevant\", \"\"), values.get(\"Company_Influence\", \"\"),\n",
    "        values.get(\"Data_Availability\", \"\"), values.get(\"Regulation\", \"\")\n",
    "    )\n",
    "\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    author = values.get(\"Author\") or values[\"Source\"]\n",
    "\n",
    "    new_row = {\n",
    "        \"Title\": values[\"Title\"],\n",
    "        #\"Source\": values[\"Source\"],\n",
    "        \"Author\": author,\n",
    "        \"NACE_Assignment\": nace_codes,\n",
    "        \"Trust_Score\": trust,\n",
    "        \"Risk_Score\": risk,\n",
    "        \"Timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "    df_updated = pd.concat([df_existing, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    try:\n",
    "        df_updated.to_excel(filename, index=False)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error writing to file\", str(e))\n",
    "        return\n",
    "\n",
    "    if not entry_already_in_gui(values[\"Title\"], values[\"Source\"]):\n",
    "        tree.insert(\"\", tk.END, values=list(new_row.values()))\n",
    "\n",
    "    messagebox.showinfo(\"Success\", \"Entry added successfully.\")\n",
    "\n",
    "# Button\n",
    "btn_add_manual = tk.Button(entry_frame, text=\"Add Entry to File\", command=add_manual_entry,\n",
    "                           font=(\"Arial\", 12), bg=\"#2196F3\", fg=\"white\", padx=10, pady=5)\n",
    "btn_add_manual.pack(pady=10)\n",
    "# --- INPUT ---\n",
    "\n",
    "# --- STATIC LEGEND ---\n",
    "legend_frame = tk.Frame(root, bg=\"#f0f4f8\", pady=10)\n",
    "legend_frame.pack(fill=\"x\", padx=10)\n",
    "\n",
    "# Trust Score Legende\n",
    "trust_label = tk.Label(\n",
    "    legend_frame,\n",
    "    text=\"Trust Score: 10 = Trusted high, 7 = Trusted medium 4 = Not trusted\",\n",
    "    font=(\"Arial\", 11),\n",
    "    bg=\"#f0f4f8\",\n",
    "    fg=\"#333\"\n",
    ")\n",
    "trust_label.pack(anchor=\"w\", padx=5)\n",
    "\n",
    "# Risk Score Legende\n",
    "risk_label = tk.Label(\n",
    "    legend_frame,\n",
    "    text=\"Risk Score: 10 = Hohes Risiko, 1 = Geringes Risiko\",\n",
    "    font=(\"Arial\", 11),\n",
    "    bg=\"#f0f4f8\",\n",
    "    fg=\"#333\"\n",
    ")\n",
    "risk_label.pack(anchor=\"w\", padx=5)\n",
    "# --- END LEGEND ---\n",
    "\n",
    "frame_table = tk.Frame(root)\n",
    "frame_table.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "columns = [\"Title\", \"Author\", \"NACE_Assignment\", \"Trust_Score\", \"Risk_Score\", \"Timestamp\"]\n",
    "tree = ttk.Treeview(frame_table, columns=columns, show=\"headings\", height=20)\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\"Treeview.Heading\", font=(\"Arial\", 11, \"bold\"))\n",
    "style.configure(\"Treeview\", font=(\"Arial\", 10))\n",
    "\n",
    "for col in columns:\n",
    "    tree.heading(col, text=col)\n",
    "    tree.column(col, anchor=\"w\", width=230)\n",
    "tree.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Watchdog handler\n",
    "class ExcelHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.src_path.endswith(\".xlsx\"):\n",
    "            df = analyze_file(event.src_path)\n",
    "            if df is not None:\n",
    "                tree.after(0, update_gui, df)\n",
    "                processed_folder = \"processed\"\n",
    "                os.makedirs(processed_folder, exist_ok=True)\n",
    "                filename = os.path.basename(event.src_path)\n",
    "                target_path = os.path.join(processed_folder, filename)\n",
    "                try:\n",
    "                    shutil.move(event.src_path, target_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error moving file: {e}\")\n",
    "\n",
    "# Update GUI with new data\n",
    "def update_gui(df):\n",
    "    for _, row in df.iterrows():\n",
    "        title = row[\"Title\"]\n",
    "        author = row[\"Author\"]\n",
    "        if not entry_already_in_gui(title, author):\n",
    "            tree.insert(\"\", tk.END, values=list(row))\n",
    "\n",
    "# Folder monitoring\n",
    "def monitor_folder(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    event_handler = ExcelHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path=path, recursive=False)\n",
    "    observer.start()\n",
    "\n",
    "monitor_thread = threading.Thread(\n",
    "    target=monitor_folder, \n",
    "    args=(\"incoming_sources\",), \n",
    "    daemon=True\n",
    ")\n",
    "monitor_thread.start()\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
